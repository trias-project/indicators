---
title: "Check correctness of wrangling data via SQLite database instead of csv"
author:
- Damiano Oldoni
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
---

# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Load libraries

Load libraries:

```{r load_libraries}
# Tidyverse packages
library(dplyr)
library(purrr)
library(readr)
# examine and clean dirty data
# handle large files
library(inborutils)
# manage databases
library(DBI)
library(RSQLite)
# GBIF related packages
library(rgbif)
```

# Species under study

We are interested in the following alien species:

species | kingdom | GBIF backbone key
--- | --- | ---
Baccharis halimifolia | Plantae | 3129663
Impatiens glandulifera | Plantae | 2891770
Impatiens capensis | Plantae | 2891774
Hydrocotyle ranunculoides | Plantae | 7978544

In data frame:
```{r alien_species_df}
alien_species <- data.frame(species = c("Baccharis halimifolia",
                                        "Impatiens glandulifera",
                                        "Impatiens capensis",
                                        "Hydrocotyle ranunculoides"),
                            taxonKey = c(3129663, 2891770,
                                         2891774, 7978544))
```

species | kingdom | GBIF backbone key
--- | --- | ---


# Occurrence data: query containing only species of interest

We triggered a download of the species mentioned above in Belgium (parameters  `country = BE`) and with geographical coordinates (`hasCoordinate = TRUE`). Download key: `0008376-181003121212138`.

```{r get_dwc_hascoord}
gbif_key <- "0008376-181003121212138"
specific_csv_file <- paste0("../data/interim/rgbif/rgbif_query_coord_", 
                                          gbif_key, ".csv")
# downloaded zip file is in subdirectory ./data/interim/rgbif
file_path <- paste0("../data/interim/rgbif/")
if (!file.exists(file_path))
  dir.create(file_path)
occ <- occ_download_get(key = gbif_key, overwrite = TRUE, path = file_path)
fn <- "occurrence.txt"
unzip(zipfile = occ, files = fn,
      exdir = "../data/interim/rgbif/.")
file.rename(from = "../data/interim/rgbif/occurrence.txt", 
            to = specific_csv_file)
```

Import text file to R:
  
```{r import_to_R_df2}
specific_csv_file_df <- read_delim(
  file = specific_csv_file, delim = "\t",
  escape_double = FALSE, trim_ws = TRUE, 
  col_types = cols(recordNumber = col_character(),
                   catalogNumber = col_character(),
                   taxonID = col_character(),
                   organismQuantity = col_character()))
```

Number of occurrences per species:
  
```{r _n_occ_per_species_query_rgbif_coord}
count_specific_csv_file_df <- specific_csv_file_df %>%
  filter(speciesKey %in% alien_species$taxonKey) %>%
  group_by(speciesKey, species) %>%
  count() %>%
  rename(n_dwc_rgbif_query_coord = n)
count_specific_csv_file_df
```

# Occurrence data: query at kingdom level

We triggered a download of all plants in Belgium (parameters  `country = BE`) and with geographical coordinates (`hasCoordinate = TRUE`).  Download key: `0003457-181003121212138`.

```{r gbif_download_key}
gbif_download_key <- "0003457-181003121212138"
```

We download the large zip files if not done already:

```{r load_occ_data}
if (!file.exists(paste0("../data/interim/", gbif_download_key, "_occurrence.txt"))) {
  occ <- occ_download_get(key = gbif_download_key, 
                          overwrite = T, path = "../data/interim/")
  fn <- "occurrence.txt"
  unzip(zipfile = occ, files = fn, exdir = "../data/interim")
  file.rename(from = "../data/interim/occurrence.txt", 
              to = paste0("../data/interim/", gbif_download_key, "_occurrence.txt"))
} else {
  paste0("File ", paste0("../data/interim/", gbif_download_key, "_occurrence.txt"),
         " already exists.")
}
```

The files are very large. We copy them to `SQLite` files (extension `.db`) via INBO utility function `csv_to_sqlite()`. If the databases already exist then a message is returned:

```{r convert_to_sqlite}
csv_file <- paste0("../data/interim/", gbif_download_key, "_occurrence.txt")
sqlite_file <- paste0("../data/interim/", gbif_download_key, "_occurrence.db")
table_name <- gbif_download_key

if (file.exists(sqlite_file)) {
  paste0("Text file ",csv_file,
         " already copied to SQLite database ", sqlite_file, ".")
} else {
  csv_to_sqlite(csv_file = csv_file, 
                sqlite_file = sqlite_file, 
                table_name = table_name, delim = "\t", 
                trim_ws = TRUE, escape_double = FALSE,
                show_progress_bar = TRUE)
}
```

Extract data for the species under study as a standard data frame:

```{r extract_occ_alien_as_df}
my_db <- src_sqlite(sqlite_file, create = FALSE)
occ_db <- tbl(my_db, table_name)
results_from_db_df <- occ_db %>% 
  # dplyr::select(one_of(cols_to_select)) %>%
    dplyr::filter(speciesKey %in% alien_species$taxonKey) %>%
    dplyr::as_tibble()
```

Number of occurrences per species:
  
```{r _n_occ_per_species_sqlite_db}
count_results_from_db_df <- results_from_db_df %>%
  group_by(speciesKey, species) %>%
  count() %>%
  rename(n_from_db = n)
count_results_from_db_df
```

Comparison:

```{r comparison_specific_vs_selection_from_sqlite_db}
comparison_table <- count_specific_csv_file_df %>%
  full_join(count_results_from_db_df, 
            by = c("speciesKey", "species"))
comparison_table
```

Sensible differences, for Impatiens glanduliera even more than 2000 occurrences.

Double check: have all occurrences valid geographical coordinates as requested in the query?

```{r check_has_coordinate}
results_from_db_df %>%
  filter(!is.na(decimalLatitude) & !is.na(decimalLongitude)) %>%
  nrow() == nrow(results_from_db_df)
```

Are there duplicates?

```{r detect_dulicates}
results_from_db_df_no_dupl <- results_from_db_df %>% 
  distinct()
nrow(results_from_db_df_no_dupl) != nrow(results_from_db_df)
```

Number of occurrences per species without counting duplicates:

```{r count_without_duplicates}
count_results_from_db_df_no_dupl <- results_from_db_df_no_dupl %>%
  group_by(speciesKey, species) %>%
  count() %>%
  rename(n_from_db_no_dupl = n)
count_results_from_db_df_no_dupl
```

Comparison without counting duplicates:

```{r comparison_specific_vs_selection_from_sqlite_db_no_dupl}
comparison_table <- count_specific_csv_file_df %>%
  full_join(count_results_from_db_df_no_dupl, 
            by = c("speciesKey", "species"))
comparison_table
```

This first analysis shows that there are duplicates in the SQLite database. 

Show dulicates:

```{r}
results_from_db_df %>% 
  group_by(gbifID) %>%
  count() %>%
  filter(n > 1) %>%
  head() %>%
  left_join(results_from_db_df, by = "gbifID")
```

