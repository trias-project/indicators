---
title: "Occurrence indicators: downscaling"
author:
- Damiano Oldoni
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
---

This document describes how to apply downscaling method on GBIF occurrence data of Invasive Alien Species.

# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Load libraries

Install `trias` package:

```{r install_packages}
devtools::install_github("trias-project/trias")
```

Load libraries:

```{r load_libraries}
# Graphic packages
library(ggplot2)
library(sf)
library(sp)
library(rgdal)
library(raster)
library(rgeos)
# Tidyverse packages
library(tidyr)
library(dplyr)
library(purrr)
library(readr)
library(stringr)
# time series package
library(zoo)
# Downscale package
library(downscale)
# GBIF related packages
library(rgbif)
# Project package
library(trias)
```

## Set coordinate reference systems

GBIF occurrence data use WGS84 projection:
```{r set_crs}
# CRS used by GBIF
wgs_84 <- st_crs("+init=epsg:4326")
```

# Get data

## Import UTM grids

First, we import UTM grids of Belgium at 5 by 5 km with CRS (Coordinate Reference System) Belge Lambert 1972:

```{r import_grids_5km}
belgium_5grid <- st_read("../data/external/utm5_bel", "utm5_bel")
crs_data <- st_crs(belgium_5grid)
``` 

## Import occurrence data

We can import test data based on a previous download related to taxa in `../data/input/species_test_invasion_curve.tsv`:

```{r load_occ_data}
if (!file.exists("../data/interim/occurrence_plants_species_test_downscaling.txt")) {
  gbif_download_key <- "0045622-180508205500799"
  occ <- occ_download_get(
    key = gbif_download_key,
    overwrite = T,
    path = "../data/interim/"
  )
  fn <- "occurrence.txt"
  unzip(
    zipfile = occ, files = fn,
    exdir = "../data/interim"
  )
  file.rename(
    from = "../data/interim/occurrence.txt",
    to = "../data/interim/occurrence_plants_species_test_downscaling.txt"
  )
}

occ_df <- read_delim(
  file = "../data/interim/occurrence_plants_species_test_downscaling.txt", "\t",
  escape_double = FALSE, trim_ws = TRUE
)
```

# Explore data

The data contain occurrences for several species:

```{r species}
occ_df %>%
  group_by(scientificName) %>%
  count() %>%
  arrange(desc(n))
```

# Preprocess data

## Explore data

Uncertainty on position is given in `coordinateUncertaintyInMeters` while in `verbatimCoordinateSystem` we can get details about the sampling methodology:

```{r}
occ_df %>%
  group_by(coordinateUncertaintyInMeters, verbatimCoordinateSystem) %>%
  count() %>%
  arrange(desc(n))
```

## Filter suspicious data

We can decide to remove suspicious occurrence data. In particular, we remove data without spatial coordinates, spatial uncertainty or temporal information (`year`):

```{r remove_with_no_position}
occ_df <- occ_df %>%
  filter(!is.na(decimalLatitude) &
    !is.na(decimalLongitude) &
    !is.na(coordinateUncertaintyInMeters) &
    !is.na(year))
```

These species remain after cleaning:

```{r species_left}
sc_names <- occ_df %>%
  distinct(scientificName) %>%
  pull()
sc_names
```

## Build presence-absence atlas data

We consider occurrence data as circles with radius equal to `coordinateUncertaintyInMeters` and centered at `decimalLatitude` and `decimalLongitude`.

First, we create points based on latitude and longitude:

```{r create_polygons}
occ_pts <- st_as_sf(occ_df,
  coords = c("decimalLongitude", "decimalLatitude"),
  crs = wgs_84
)
```

We can then create circles based on `coordinateUncertaintyInMeters` as radius:

```{r create_circles}
# transform to Lamber 1972
occ_pts_lambert <- st_transform(occ_pts, crs_data)
occ_pts_lambert <- st_buffer(occ_pts_lambert,
  dist = occ_pts_lambert$coordinateUncertaintyInMeters,
  nQuadSegs = 6
)
```

We intersect occurrence circles with the grid per each species and year:

```{r intersection}
spatial_fit <- st_intersection(belgium_5grid, occ_pts_lambert)

oar <- spatial_fit %>%
  mutate(
    n_float =
      as.numeric(st_area(.)) / (coordinateUncertaintyInMeters^2 * pi)
  ) %>%
  group_by(scientificName, year, TAG) %>%
  summarize(n = round(sum(n_float))) %>%
  arrange(desc(n))
```

We assign 1 (presence) to the squares with at least one occurrence, 0 otherwise:

```{r assign_to_centroids}
pres_abs_table <- belgium_5grid %>%
  crossing(data.frame(year = seq(
    min(oar$year, na.rm = TRUE),
    max(oar$year, na.rm = TRUE)
  ))) %>%
  crossing(data.frame(
    scientificName = sc_names,
    stringsAsFactors = FALSE
  )) %>%
  left_join(data.frame(oar, stringsAsFactors = FALSE) %>%
    dplyr::select(scientificName, year, TAG, n),
  by = c("scientificName", "year", "TAG")
  ) %>%
  mutate(presence = ifelse(!is.na(n) & n > 0, 1, 0))
```

A presence-absence table per species and year is thus formed and ready to be used as input for downscaling modelling.

# Downscaling

## Select species 

It would not have sense to apply downscaling to species occurring in less than 10 percentage of the squares (`n1_threshold`). For this reason we 

```{r species_in_more_than_n1_threshold_squares}
n1_threshold <- nrow(belgium_5grid) / 100 * 10
species <- pres_abs_table %>%
  as.data.frame() %>%
  filter(presence == 1) %>%
  group_by(scientificName) %>%
  distinct(TAG) %>%
  count() %>%
  mutate(accept = if_else(n >= n1_threshold, TRUE, FALSE)) %>%
  filter(isTRUE(accept)) %>%
  pull(scientificName)
species
```

Species not included in downloading:

```{r overview_excluded_species}
sc_names[which(!sc_names %in% species)]
```

```{r filter_out_excluded_species_info}
pres_abs_table <- pres_abs_table %>%
  filter(scientificName %in% species)
```

## Temporal distribution

We are interested on how occupancy varies with time.

### Explore temporal distribution

Temporal distribution histogram of each species:

```{r temporal_distribution}
occ_df <- occ_df[occ_df$scientificName %in% species, ]
ggplot(
  occ_df,
  aes(year)
) +
  geom_histogram(binwidth = 1) +
  facet_wrap(~scientificName, ncol = 3)
```

The temporal variability is very high due to changes in survey efforts. Such variability risks to covers variations in aliean species spreading. So, for each species and square, we aggregate data within a moving time window. We use a window of 5 years. A longer time window would be not policy relevant:

```{r time_window}
t_window <- 5
```

```{r running_aggregation}
pres_abs_table_mov_sum <- pres_abs_table %>%
  group_by(scientificName, TAG) %>%
  mutate(mov_sum = c(
    rep(0, t_window - 1),
    rollsum(na.fill(n, 0), t_window, align = "right")
  )) %>%
  ungroup() %>%
  mutate(presence = if_else(mov_sum > 0, 1, 0))
```

This moving sum smoothing technique results in the following temporal distribution:

```{r temporal_distribution,  echo = FALSE}
data_mov_sum <- occ_df %>%
  group_by(scientificName, year) %>%
  count() %>%
  ungroup()

data_mov_sum_tidy <- crossing(
  data.frame(
    scientificName = unique(data_mov_sum$scientificName),
    stringsAsFactors = FALSE
  ),
  data.frame(year = seq(
    min(data_mov_sum$year, na.rm = TRUE),
    max(data_mov_sum$year, na.rm = TRUE)
  ))
) %>%
  left_join(data_mov_sum,
    by = c("scientificName", "year")
  ) %>%
  group_by(scientificName) %>%
  mutate(mov_sum = c(
    rep(0, t_window - 1),
    rollsum(na.fill(n, 0), t_window, align = "right")
  )) %>%
  ungroup()

ggplot(
  data_mov_sum_tidy,
  aes(x = year, y = mov_sum)
) + ylab("n. records") +
  geom_bar(stat = "identity") +
  facet_wrap(~scientificName, ncol = 3)
```

Downscaling tends to underestimate occupancy if less than 2.5% percentage of squares (`n2_threshold`) are occupied. We apply downscaling to years and species when number of occupied squares are above this threshold. The moving sum could increase the number of occupied squares, thus reducing the situations when downscaling is not applicable:

```{r second_threshold}
n2_threshold <- round(nrow(belgium_5grid) / 100 * 2.5)
```

```{r select_species_year_above_second_threhsold}
# combinations species-year to select
species_year <- pres_abs_table_mov_sum %>%
  as.data.frame() %>%
  filter(presence == 1) %>%
  group_by(scientificName, year) %>%
  count() %>%
  ungroup() %>%
  rename(number_of_squares = nn) %>%
  filter(number_of_squares > n2_threshold)
species_year
```

```{r}
pres_abs_tag_year <- pres_abs_table_mov_sum %>%
  right_join(species_year,
    by = c("scientificName", "year")
  )
```


## Apply downscaling

We apply first an upgraining, then we proceed with downscaling. See documentation package [`downscale`](https://cran.r-project.org/web/packages/downscale/downscale.pdf).

### Prepare input data 

Assign presence-absence table to centroids:

```{r centroids}
pres_abs_tag_year_ctds <- st_centroid(pres_abs_tag_year)
```

### Upgraining

Apply `upgrain.threshold()` to estimate the best threshold method. We use two scaling levels (we upgrain from 5 by 5 to 10 by 10 and 20 by 20). As explained in `vignette("Upgraining", package = "downscale")`:

>a larger number of scales means there is more data to fit the downscaling models, however the larger discrepancy there will be between the original extent of the atlas data and the new standardised extent.

In case of small extent (Belgium is relatively small) this discrepancy can easily become very large. So, we don't recommend any further upgraining. Here below we show the effects of choosing different thresholds for _Fallopia japonica (Houtt.) Ronse Decraene_ and period 2013-2017:

```{r apply_upgrain_threshold}
test <- pres_abs_tag_year_ctds %>%
  filter(scientificName ==
    "Fallopia japonica (Houtt.) Ronse Decraene") %>%
  filter(year == 2013)
test <- as(test, "Spatial")
test@data <- data.frame(test@data$presence)
get_upgrain_values <- upgrain.threshold(
  test,
  cell.width = 5000,
  scales = 2,
  thresholds = seq(0, 1, 0.01)
)
```

Apply threshold method `All_Occurrences` with scales equal to 2 for all species and years:

```{r upgrain}
progress_bar <- progress_estimated(nrow(species_year))
upgrain_species_year <- map2(
  species_year$scientificName,
  species_year$year,
  function(x, y) {
    progress_bar$tick()$print()
    points <- pres_abs_tag_year_ctds %>%
      filter(scientificName == x) %>%
      filter(year == y)
    points <- as(points, "Spatial")
    points@data <- data.frame(points@data$presence)
    upgrain(points,
      scales = 2,
      cell.width = 5000,
      method = "All_Occurrences",
      plot = FALSE
    )
  }
)
names(upgrain_species_year) <- str_c(species_year$scientificName,
  species_year$year,
  sep = "_"
)
```

We select the five simplest downscale models, which have been used in Groom at al. 2018 in order to form the so called _simple ensemble_: power law, Nachman, Poisson, logistic and negative binomial.

```{r models}
models_simple_ensemble <- c("Nachman", "PL", "Poisson", "Logis", "NB")
```

and cell resolution 1x1km, 2x2km and 5x5km: 

```{r cell_areas}
# 1x1km, 2x2, 5x5
areas <- c(10^6, 4 * 10^6, 25 * 10^6)
```


Run downscaling:

```{r apply_downscaling_models}
progress_bar <- progress_estimated(length(upgrain_species_year))
downscaling <- map(upgrain_species_year, ~ {
  progress_bar$tick()$print()
  ensemble.downscale(.,
    new.areas = areas,
    models = models_simple_ensemble,
    verbose = FALSE,
    plot = FALSE
  )
})
```

We tidy the data:

```{r calculate_std}
downscaling_tidy <- map(
  names(downscaling), function(x) {
    downscaling[[x]]$Occupancy %>%
      mutate(
        scientificName = str_split(x, pattern = "_")[[1]][1],
        year = as.integer(str_split(x, pattern = "_")[[1]][2])
      )
  }
)
downscaling_tidy <- bind_rows(downscaling_tidy) %>%
  gather_(key = "method", value = "occupancy", c(models, "Means"))

downscaling_tidy <- crossing(
  data.frame(
    scientificName = species,
    stringsAsFactors = FALSE
  ),
  year = seq(
    min(downscaling_tidy$year, na.rm = TRUE),
    max(downscaling_tidy$year, na.rm = TRUE)
  )
) %>%
  left_join(data.frame(downscaling_tidy,
    stringsAsFactors = FALSE
  ),
  by = c("scientificName", "year")
  )
```

We save the occupancies:

```{r save_occupancy}
write_tsv(downscaling_tidy,
  path = "../data/output/downscaling_tidy.tsv"
)
```

And plot them for each taxa at 1 square kilometer (`Cell.area` equal to 1.0e+06):

```{r plot_occupancy}
cell_area <- 1.0e+06
occupancy_plots <- map(
  species, function(species_name) {
    ggplot(
      downscaling_tidy %>%
        filter(scientificName == species_name &
          is.finite(occupancy) &
          Cell.area == cell_area),
      aes(x = year, y = occupancy, colour = method)
    ) +
      geom_line() +
      geom_point() +
      ggtitle(species_name)
  }
)
occupancy_plots
```

The same at 2 square kilometer (`Cell.area` equal to 4.0e+06):

```{r plot_occupancy}
cell_area <- 4.0e+06
occupancy_plots <- map(
  species, function(species_name) {
    ggplot(
      downscaling_tidy %>%
        filter(scientificName == species_name &
          is.finite(occupancy) &
          Cell.area == cell_area),
      aes(x = year, y = occupancy, colour = method)
    ) +
      geom_line() +
      geom_point() +
      ggtitle(species_name)
  }
)
occupancy_plots
```
